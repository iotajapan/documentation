# Apache Flinkを使用してZMQイベントをほぼリアルタイムで処理する
<!-- # Process ZMQ events in near real-time with Apache Flink -->

**ZMQイベントを購読すると、ノードからほぼリアルタイムでタングルデータを受信できます。このデータを処理するために、オープンソースのApache Flinkなどのストリーム処理フレームワークを使用できます。**
<!-- **When you subscribe to ZMQ events, you receive near real-time Tangle data from a node. To process this data, you can use a stream processing framework such as the open-source [Apache Flink](https://flink.apache.org/).** -->

このガイドでは、FlinkでZMQデータを処理するために[Flink タングルソースライブラリ](https://github.com/Citrullin/flink-tangle-source)を使用します。
<!-- This guide uses the [Flink Tangle source library](https://github.com/Citrullin/flink-tangle-source) to use process ZMQ data with Flink. -->

このライブラリは、[タングルストリーミングライブラリ](https://github.com/Citrullin/tangle-streaming)の[ZeroMQMessageParser](https://github.com/Citrullin/tangle-streaming/blob/master/src/main/scala/org/iota/tangle/stream/ZeroMQMessageParser.scala)を使用して、生のイベントメッセージをクラスインスタンスへパースします。
すべてのZMQイベントメッセージは、[Protocol Buffersスキーマファイル](https://github.com/Citrullin/tangle-streaming/tree/master/src/main/protobuf)によって生成されたクラスにラップされています。全てのProtocol Buffersメッセージと属性はFlinkでも利用可能です。
<!-- This library uses the [ZeroMQMessageParser](https://github.com/Citrullin/tangle-streaming/blob/master/src/main/scala/org/iota/tangle/stream/ZeroMQMessageParser.scala) from the [Tangle streaming library](https://github.com/Citrullin/tangle-streaming) to parse the raw event messages into class instances. -->
<!-- All ZMQ event messages are wrapped in classes that are generated by [protobuf schema files](https://github.com/Citrullin/tangle-streaming/tree/master/src/main/protobuf). All protobuf messages and attributes are also available in Flink. -->

このライブラリはZMQ APIを使用しているため、すべての[ZMQイベント](../references/zmq-events.md)を処理に使用できます。
<!-- Because this library uses the ZMQ API, all [ZMQ events](../references/zmq-events.md) are available for processing. -->

:::info:
このガイドのタングルストリーミングライブラリは、運用環境にはお勧めできません。
ライブラリー開発に貢献してください。そうすれば、最終的に運用準備が整います。
:::
<!-- :::info: -->
<!-- The Tangle streaming libraries in this guide are not recommended for production environments. -->
<!-- Feel free to contribute to the libraries, so that they eventually become production ready. -->
<!-- ::: -->

## 前提条件
<!-- ## Prerequisites -->

このガイドを完成するには、次のものが必要です。
<!-- To complete this guide, you need the following: -->

- **オペレーティングシステム：** Linux、MacOS、BSDまたはWindows
<!-- - **Operating system:** Linux, MacOS, BSD or Windows -->
- **RAM：** 2GB
<!-- - **RAM:** 2GB -->
- **ストレージ：** 10GBの空き容量
<!-- - **Storage:** 10GB free space -->

このガイドでは、Scalaプログラミング言語とsbtビルドツールを使用します。
<!-- This guide uses the Scala programming language with the sbt build tool. -->

Java Runtime Environment（JRE）でScalaを使用したい場合は、Scalaライブラリを[Maven](https://mvnrepository.com/artifact/org.scala-lang/scala-library)または[sbt](http://xerial.org/blog/2014/03/24/sbt/)に追加する必要があります。
<!-- If you want to use Scala in a Java Runtime Environment (JRE), you need to add the Scala library to [Maven](https://mvnrepository.com/artifact/org.scala-lang/scala-library) or [sbt](http://xerial.org/blog/2014/03/24/sbt/). -->

この[Artimaガイド](https://www.artima.com/pins1ed/combining-scala-and-java.html)はJREでScalaをどのように使えるかを説明しています。
<!-- This [Artima guide](https://www.artima.com/pins1ed/combining-scala-and-java.html) describes how you can use Scala in a JRE. -->

## ライブラリをダウンロードしてインストールする
<!-- ## Download and install the libraries -->

1. [Javaをインストールします](http://openjdk.java.net/install/)。ScalaはJava仮想マシンを使用するため、Java 8以降をインストールする必要があります。
  <!-- 1. [Install Java](http://openjdk.java.net/install/). Because Scala uses the Java virtual machine, you must install Java 8 or higher. -->

2. [sbtをインストールします](https://www.scala-sbt.org/1.x/docs/Setup.html)。
  <!-- 2. [Install sbt](https://www.scala-sbt.org/1.x/docs/Setup.html) -->

3. ライブラリをクローンします。
  <!-- 3. Clone the libraries -->

  ```bash
  git clone https://github.com/Citrullin/tangle-streaming.git
  git clone https://github.com/Citrullin/flink-tangle-source
  ```

4. `tangle-streaming`ディレクトリに移動してREPL（Read-Evaluate-Print Loop）を初期化します。
  <!-- 4. Change into the `tangle-streaming` directory and initialize the REPL (Read-Evaluate-Print Loop) -->

  ```bash
  cd tangle-streaming && sbt
  ```

5. REPLで、ライブラリをビルドします。
  <!-- 5. In the REPL, build the library -->

  ```bash
  compile
  publishLocal
  ```

6. **Ctrl** + **C**を押してREPLを終了します。
  <!-- 6. Press **Ctrl** + **C** to terminate the REPL -->

7. `flink-tangle-source`ディレクトリに移動してREPLを初期化します。
  <!-- 7. Change into the `flink-tangle-source` directory and initialize the REPL -->

  ```bash
  cd ../flink-tangle-source && sbt
  ```

8. REPLで、ライブラリをビルドします。
  <!-- 8. In the REPL, build the library -->

  ```bash
  compile
  publishLocal
  ```

9. `build.sbt`ファイルに依存関係を追加します。
  <!-- 9. Add the dependencies to the `build.sbt` file -->

  ```scala
  libraryDependencies += "org.iota" %% "flink-tangle-source" % "0.0.1",
  ```

:::success:
ライブラリをダウンロードしてインストールしたので、ZMQデータを処理するためにライブラリを使用し始めることができます。
[ここ](https://github.com/iota-community/flink-tangle-examples)にいくつかの例があります。
:::
<!-- :::success: -->
<!-- Now that you've downloaded and installed the libraries you can start using them to process ZMQ data. -->
<!-- We have [some examples available here](https://github.com/iota-community/flink-tangle-examples). -->
<!-- ::: -->

:::info:
独自のIRIノードを実行している場合は、[ZMQ設定パラメータを有効にする](../references/iri-configuration-options.md)必要があります。

[Tanglebeat](http://tanglebeat.com/page/internals)はZMQが有効になっているパブリックノードの一覧を提供します。

現時点ではcIRIはZMQ APIをサポートしていません。
:::
<!-- :::info: -->
<!-- If you run your own IRI node, you have to [enable the ZMQ configuration parameter](../references/iri-configuration-options.md). -->
<!--  -->
<!-- [Tanglebeat provides a list of public nodes that have ZMQ enabled.](http://tanglebeat.com/page/internals). -->
<!--  -->
<!-- cIRI does not support the ZMQ API at the moment. -->
<!-- ::: -->

## 過去1時間に最も使用された上位10のアドレスを処理する
<!-- ## Process the top 10 most used addresses in the last hour -->

ZMQイベントストリームのデータを使用して、過去1時間で最も使用された上位10のアドレスを見つけることができます。
<!-- You can use the data in ZMQ event streams to find out the top 10 most used addresses in the last hour. -->

このガイドのソースコードは、[IOTAコミュニティのGitHubリポジトリ](https://github.com/iota-community/flink-tangle-examples)の`MostUsedAddresses.scala`ファイルにあります。
<!-- This code in this guide is available in the `MostUsedAddresses.scala` file on [this IOTA community GitHub repository](https://github.com/iota-community/flink-tangle-examples). -->

## 前提条件
<!-- ## Prerequisites -->

Flinkに慣れていない場合は、[このドキュメント](https://ci.apache.org/projects/flink/flink-docs-release-1.8/tutorials/datastream_api.html)をお読みください。
<!-- If you are not familiar with Flink, you should read [this documentation](https://ci.apache.org/projects/flink/flink-docs-master/tutorials/datastream_api.html#writing-a-flink-program). -->

[ライブラリをダウンロードしてインストール](#ライブラリをダウンロードしてインストールする)しておく必要があります。
<!-- You must have [downloaded and installed the libraries](#download-and-install-the-libraries). -->

---

ノードに接続してストリームを設定します。
<!-- Set up the stream by connecting to a node -->

```scala
val unconfirmedMessageDescriptorName = UnconfirmedTransactionMessage.scalaDescriptor.fullName
val zeroMQHost = "HOSTNAME|IP"
val zeroMQPort = config.getInt(ConfigurationKeys.ZeroMQ.port)
val env: StreamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment

val stream = env.addSource(new TangleSource(zeroMQHost, zeroMQPort, ""))
```

:::info:
ここでは、ホスト名とポートでノードに接続します。[tx](../references/zmq-events.md#tx)イベントなどの特定のトピックを購読することができます。

```scala
val stream = env.addSource(new TangleSource(zeroMQHost, zeroMQPort, "tx"))
```
:::

<!-- :::info: -->
<!-- Here, we connect to a node by its hostname and port. We could subscribe to a specific topic such as the [tx](../references/zmq-events.md#tx) event: -->
<!--  -->
<!-- ```scala -->
<!-- val stream = env.addSource(new TangleSource(zeroMQHost, zeroMQPort, "tx")) -->
<!-- ``` -->
<!-- ::: -->

GeneratedMessageのストリームを取得するので、[Protocol Buffers記述子](https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.descriptor)を使ってフィルタリングする必要があります。
<!-- Since we get a stream of GeneratedMessage, we need to filter with the [protobuf descriptor](https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.descriptor). -->

```scala
val filteredStream = stream
  .filter(_.companion.scalaDescriptor.fullName == unconfirmedMessageDescriptorName)
```

これにより、ストリームにUnconfirmedTransactionMessagesのみが含まれるようになります。
型をチェックし、ストリームをオプションでラップして値を取得します。
すでにディスクリプタをフィルタリングしているので、すべてのイベントはUnconfirmedTransactionMessage型であることがわかります。
そうでない場合、基本的なことが間違っており、NullPointerExceptionが発生するとアプリケーションがクラッシュします。
<!-- We can make sure with this that the stream only contains UnconfirmedTransactionMessages. -->
<!-- So now we check the type, wrap it in an option and getting the value. -->
<!-- Since we already filtered on the descriptor, we know that every event is of type UnconfirmedTransactionMessage. -->
<!-- If not, something fundamental is wrong and a NullPointerException will crash the application. -->

```scala
val unconfirmedTransactionStream = filteredStream.map(_ match {
        case m: UnconfirmedTransactionMessage => Some(m)
        case _ => None
      })
      .map(_.get)
```

これは一般的でない方法です。 `NullPointer`例外が発生する可能性があるため、決してgetを使用しないでください。
代わりに[getOrElse](https://www.tutorialspoint.com/scala/scala_options.htm)を使用してください。
正しい型が返されるように、ライブラリにフィルタを実装することも意味があります。
これは型チェックを時代遅れにするでしょう。
このライブラリはPoCにすぎないので、当面はこの解決策を使用します。
<!-- This is a uncommon and dirty way to do. You should never use get, since you can run into `NullPointer` exceptions. -->
<!-- Use [getOrElse](https://www.tutorialspoint.com/scala/scala_options.htm) instead. -->
<!-- It would also make sense to implement a filter into the library, so that the correct type is returned. -->
<!-- That would make the type checking obsolete. -->
<!-- Since this library is just a proof of concept, we go with this dirty solution for now. -->

これで、UnconfirmedTransactionMessage型のストリームができました。
基本的に、フルノードが受信するすべてのメッセージを受け取り、どのアドレスが最も多く使用されたかを調べます。
つまり、アドレスとカウンターがあれば十分です。
簡単にするために、トランザクション内のすべてのアドレスを1つとして数えます。
また入力しか保存できませんでした。
二重に使用されているアドレスを検出するために、出力をフィルタリングすることもできます。
出力をフィルタリングする場合は、`value > 0`または`value < 0`のフィルタを適用する必要があります。
<!-- Now we have our stream of the type UnconfirmedTransactionMessage. -->
<!-- We basically get every message our full-node receives. -->
<!-- We want to find out which addresses were used the most. -->
<!-- That means, we only need the address and some counter. -->
<!-- For simplicity we count every address in a transaction as one. -->
<!-- We could also only keep the inputs. -->
<!-- To detect double used addresses, we can also filter on outputs. -->
<!-- If you want to do that, you have to apply a filter with value > 0 or value < 0. -->

```scala
val addressOnlyStream = unconfirmedTransactionStream.map(e => (e.address, 1L))
```

このような単純な関数です。この単純なmap関数を使って要素の構造を変更します。
アドレスとカウンターを保管するだけです。[タプル](https://docs.scala-lang.org/tour/tuples.html)はこれに役立ちます。
<!-- Simple as that. We change the structure of our element with this simple map function. -->
<!-- We only keep the address and a counter. [Tuples](https://docs.scala-lang.org/tour/tuples.html) are useful for this. -->

要素を数えたいのでアドレスによってストリームを合わせることができる。
これにより、アドレスで区切られたKeyedStreamが得られます。
より複雑なユースケースには[windowAll](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/windows.html#window-assigners)を使うことができます。
<!-- Since we want to count our elements, we can key our stream by the address. -->
<!-- This gives us a KeyedStream partitioned by the address. -->
<!-- For more complex use-cases you can use [windowAll](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/windows.html#window-assigners) -->

```scala
val keyedStream = addressOnlyStream.keyBy(_._1)
```

そして、すべてのパーティションに同じ種類のタプルしか含まれていないKeyedStreamができます。
基本的に同じアドレスと1Lのタプルがたくさんできます。
大量のデータを処理したい場合は、パーティション化が便利です。
Flinkはクラスタ内の異なるノード上の各パーティションに対してプロセッサを実行することができるので、各ストリームのプロセス関数は並行して動作することができます。
したがって、水平方向にスケールすることができます。
<!-- So, now we have a KeyedStream where every partition only contain some tuples of the same kind. -->
<!-- Basically a lot of tuples with the same address and 1L. -->
<!-- Partitioning is useful if you want to process a huge amount of data. -->
<!-- Flink can execute the processor for each partition on different nodes in your cluster, so that the process functions -->
<!-- on each stream can work in parallel. -->
<!-- Therefore you are able to scale horizontally. -->

次に、1時間以内のアドレスごとのトランザクション数を計算する必要があります。
スライディングウィンドウはこれに役立ちます。今回のユースケースでは、30秒の更新間隔で問題ありません。
<!-- Next, we need to calculate the number of transactions for each address within one hour. -->
<!-- Sliding Windows are useful for this. An update interval of 30 seconds is fine for our use-case. -->

```scala
val keyedTimedWindow = keyedStream.timeWindow(Time.minutes(60), Time.seconds(30))
```

これでkeyedTimeWindowsを入手しました。次にパーティションを集約する必要があります。
これには2つの選択肢があります。最もシンプルな変形はreduce関数です。
reduce関数は、すべての要素を実際に必要な数に減らす関数です。
今回のケースにおけるreduce関数は以下のようになります。
<!-- We got our keyedTimeWindows. Now we need to aggregate our partitions. -->
<!-- We have two options for this. The simplest variant is the reduce function. -->
<!-- This is a function which reduces all elements to the few we really need. -->
<!-- In our case, this would be our reduce function: -->

```scala
val aggregatedKeyedTimeWindow = timedWindow.reduce((a, b) => (a._1, a._2 + b._2))
```

このような単純な関数です。もう1つの変形は集約関数です。次が一例です。
<!-- Simple as that. The other variant is an aggregation function. One example: -->

```scala
val aggregatedKeyedTimeWindow = keyedTimedWindow.aggregate(new AddressCountAggregator)
```

AddressCountAggregatorクラスは以下の通りです。
<!-- The AddressCountAggregator class -->

```scala
class AddressCountAggregator extends AggregateFunction[(String, Long), (String, Long), (String, Long)]
{
  override def add(value: (String, Long), accumulator: (String, Long)): (String, Long) =
    (value._1, value._2 + accumulator._2)

  override def createAccumulator(): (String, Long) = ("", 0L)

  override def getResult(accumulator: (String, Long)): (String, Long) = accumulator

  override def merge(a: (String, Long), b: (String, Long)): (String, Long) = (a._1, a._2 + b._2)
}
```

結果を減らす必要があるときはいつでもreduce関数が使われます。合計が良い例です。
したがって、今回の場合、reduce関数は集約関数よりも意味があります。
集約関数は、複雑な操作があるときに役立ちます。
1つの複雑な例が[BundleAggregation.scala](https://github.com/iota-community/flink-tangle-examples/blob/master/src/main/scala/org/iota/tangle/flink/examples/BundleAggregation.scala)にあります。
BundleAggregationは入ってくるトランザクションをバンドルにまとめ、それらをUnconfirmedBundlesとReattachedUnconfirmedBundlesに分割します。
この例は単純化したもので、バンドルを正確な方法で分割するものではありません。
<!-- The reduce function is used whenever you just need to reduce your result. Sums are a good example. -->
<!-- Therefore in our case the reduce function makes more sense than the aggregation function. -->
<!-- Aggregation functions are helpful when you have complex operations. -->
<!-- You can find one more complex example in [BundleAggregation.scala](https://github.com/iota-community/flink-tangle-examples/blob/master/src/main/scala/org/iota/tangle/flink/examples/BundleAggregation.scala). -->
<!-- The BundleAggregation combines incoming transaction into a Bundle and split them into UnconfirmedBundles and ReattachedUnconfirmedBundles. -->
<!-- This example is a simplification and does not split the Bundles in an accurate way. -->

次に、すべての要素を集約して、上位10のアドレスを見つけます。
timeWindowAll関数はAllWindowedStreamを返します。
そのため、すべての要素が1つのストリームにまとめられます。
パーティションでSlidingWindowを使用したので、ここでの時間はそれほど重要ではありません。
よって、1秒を使います。
<!-- Next we want to aggregate all elements and want to find the top ten addresses. -->
<!-- The timeWindowAll functions returns a AllWindowedStream. -->
<!-- So all elements are combined in one stream again. -->
<!-- Since we used a SlidingWindow on our partitions before, the time here is not that important anymore. -->
<!-- So, we just use one second. -->

```scala
val timeWindowAll = aggregatedKeyedTimeWindow
      .timeWindowAll(Time.seconds(1))
```

ここでのAllWindowedStreamはタプル内のすべてのreduceされたパーティションを含みます。
各パーティションは、構造（ADDRESS、AMOUNT_OF_TRANSACTIONS）内に1つのタプルを持っています。
最後のステップは、どのアドレスが最も使用されているかを調べることです。
そのために集約関数を使います。
<!-- Our AllWindowedStream contains all reduced partitions in a tuple. -->
<!-- Each partition has one tuple in the structure (ADDRESS, AMOUNT_OF_TRANSACTIONS). -->
<!-- The last step is to find out which addresses are used the most. -->
<!-- So we use an aggregation function for this. -->

```scala
val mostUsedStream = timeWindowAll.aggregate(new MostUsedAddressesAggregator(10))
```

MostUsedAddressesAggregatorクラスは以下の通りです。
<!-- The MostUsedAddressesAggregator class -->

```scala
class MostUsedAddressesAggregator(number: Int) extends AggregateFunction[(String, Long), Map[String, Long], List[(String, Long)]]
{
  override def add(value: (String, Long), accumulator: Map[String, Long]): Map[String, Long] = {
    accumulator ++ Map(value._1 -> (value._2 + accumulator.getOrElse(value._1, 0L)))
  }

  override def createAccumulator(): Map[String, Long] = Map()

  override def getResult(accumulator: Map[String, Long]): List[(String, Long)] =
    accumulator.toList.sortWith(_._2 > _._2).take(number)

  override def merge(a: Map[String, Long], b: Map[String, Long]): Map[String, Long] = {
    val seq = a.toSeq ++ b.toSeq
    val grouped = seq.groupBy(_._1)
    val mapWithCounts = grouped.map{case (key, value) => (key, value.map(_._2))}

    mapWithCounts.map{case (key, value) => (key, value.sum)}
  }
}
```

Mapをアキュムレータとして使います。マップはキーとバリューのペアを含んでいるので、本当に便利です。
AggregateFunctionは一番上のアドレスから一番下のアドレスへソートされたリストを返します。
最初の10個だけに興味があるので、最初の10個だけを取ります。
クラスのコンストラクタは10を取ります。
<!-- We use a Map as accumulator. Maps are really useful, since they contain key value pairs. -->
<!-- AggregateFunction returns a sorted List. From the top used address to the bottom one. -->
<!-- We are only interested in the first ten, so we only take the first 10. -->
<!-- The constructor of the class takes the number for it. -->

最後のステップは簡単で、リストをプリントしてプログラムを実行します。
<!-- The last step is simple, print the List and execute our program. -->

```scala
mostUsedStream.print()

    // execute program
    env.execute("Most used addresses")
```
